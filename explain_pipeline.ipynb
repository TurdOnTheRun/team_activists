{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Import `joblib` from `sklearn.externals` and `numpy` as `np`, `pandas` as `pd` and `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model\n",
    "\n",
    "We use `joblib.load()` to load and store the model file 'stolen_model.pkl'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('stolen_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 attributes class 1\n",
    "\n",
    "To extract the top 10 attributes leading to one class, we take advantage of our knowledge about the underlying pipeline. The pipeline has a step named `'lin_svc'` that contains the support vector machine. We use `named_steps[]` to get this step from the pipeline and call `coef_[0]` to receive the coefficients/weights from the SVM. - and store the results into a variable called 'weights'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.named_steps['lin_svc'].coef_[0]\n",
    "weights = weights.toarray()\n",
    "sorted_index = np.argsort(weights[0])[::-1]\n",
    "#print(sorted_index)\n",
    "top_10 = sorted_index[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the weights we are interested in, we need to connect them to the corresponding terms. Get the named step `'tfidv'` from the pipeline and call `get_feature_names()` to store the terms as a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = model.named_steps['tfidv'].get_feature_names()\n",
    "#print(terms)\n",
    "for ind in top_10:\n",
    "    print(terms[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 attributes class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also extract the top 10 attributes determining the second class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.named_steps['lin_svc'].coef_[0]\n",
    "weights = weights.toarray()\n",
    "sorted_index = np.argsort(weights[0])[::1]\n",
    "#print(sorted_index)\n",
    "top_10 = sorted_index[:10]\n",
    "terms = model.named_steps['tfidv'].get_feature_names()\n",
    "#print(terms)\n",
    "for ind in top_10:\n",
    "    print(terms[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIME (Local Interpretable Model-agnostic Explanations) is a novel explanation technique that explains the prediction of any classifier in an interpretable and faithful manner by learning a interpretable model locally around the prediction.\n",
    "\n",
    "We create list of size 2 with the elements 'activist' and 'public' in this order and assign it to `class_names` and a LimeTextExplainer(), passing `class_names = class_names`. We use the `explain_instance` function (pass a text to explain as the first argument, `model.predict_proba` and `num_features=10`) and save the result to exp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "class_names = ['activist','public']\n",
    "explainer = LimeTextExplainer(class_names = class_names)\n",
    "exp= explainer.explain_instance(\"Das ist ein Test\", model.predict_proba,num_features=10)\n",
    "print('Probability: =', model.predict_proba([\"Das ist ein Test\"]))\n",
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the built-in lime visualizations\n",
    "%matplotlib inline\n",
    "fig = exp.as_pyplot_figure()\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eli5\n",
    "\n",
    "**eli5** is a python package that has been built on top of lime and a couple of other explainable AI projects. We use eli5's `show_weights()` function, giving it the named step 'lin_svc' as first argument and as `vec`. Additionally, we define the number of features we are interested in by setting `top` to an integer of our choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use eli5 to show the top N features contributing to one class\n",
    "import eli5\n",
    "eli5.show_weights(model.named_steps['lin_svc'], vec=model.named_steps['tfidv'], top=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the eli5 function `show_prediction()` with the named step 'lin_svc' as first argument, any string as the second argument and `vec=model.named_steps['tfidv']` to visualize the most important features for a sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(model.named_steps['lin_svc'], \"Das ist ein Test\", vec=model.named_steps['tfidv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## send your candidate messages to the server for evaluation\n",
    "Use backdoor.py (either paste the code in here or execute it separately)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save your candidate messages\n",
    "Save your messages as a .csv using the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [['message 1'], \n",
    "            ['message 2'], \n",
    "            ['message 3'], \n",
    "            ['message 4'], \n",
    "            ['message 5'], \n",
    "            ['message 6'], \n",
    "            ['message 7']] \n",
    "df = pd.DataFrame(messages)\n",
    "df.to_csv(\"your_team.csv\", encoding='utf-8', quoting=csv.QUOTE_ALL,header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
